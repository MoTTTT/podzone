# Implementation Notes

## Decisions

- Microk8s Kubernetes distribution
- Build tools (kubectl, calicoctl, ansible etc) on dolmen workstation
- k8s IOT Edge on anasazi RPi
- Use nfs on sigiriya for persistent storage
- Secure ingress host based routing

## Network

- Fibre router: Static IPs for control plane and worker nodes
- Fibre router: (As-is) Dynamic DNS for ```qsolutions.endoftheinternet.org```
- Fibre router: Port forwarding: 443 to k8s L2 loadbalancer (As-is goes to dolmen)
- Fibre router: Restrict DHCP IP allocation range for clients to `192.168.0.2 - 192.168.0.120`
- MetalLB: IP address range: `192.168.0.131-192.168.0.140`
- DynDns: Add wildcard routes for all internet hosts in inventory, e.g. ```*.southern.podzone.net```
- DynDns: Update IP address using ddclient
- To dev, test and debug ingress, add: qapps.does-it.net

## Node installations

- For levant, to fix calico vxlan missing dependency: `sudo apt install linux-modules-extra-raspi`
- For RiPi: Add to /boot/firmware/cmdline.txt: `cgroup_enable=memory cgroup_memory=1 net.ifnames=1 `
- Ubuntu Server and Desktop: `sudo snap install microk8s --classic`
- Ubuntu Core: `sudo snap install microk8s --channel=latest/edge/strict`
- If required to prevent deployment to RPi arch (e.g. Opensearch): `kubectl taint nodes levant key1=value1:NoSchedule`

## Cluster configuration

Enable dashboard and rbac microk8s add-ons.



### Ingress configuration

MetalLB is used to implement an L2 load balancer. The metallb micrik8s add-on is required:

`sudo microk8s enable metallb ; Set 192.168.0.131-192.168.0.132`

An ingress controller is required. De-facto standard seems to be ingress-nginx.

NOTE: Enabling the micrik8s add-on failed to produce a working ingress for me, I believe because of namespace issues.

Load ingress-nginx using helm:
  
`helm upgrade --install ingress-nginx ingress-nginx --repo https://kubernetes.github.io/ingress-nginx --namespace ingress-nginx --create-namespace`

Per-host ingress configuration is applied via the kubernetes API. Configuration is per internet host in the inventory. For implementation details see the following files in config/ directory:

- `podzone-control-ingress.yaml`
- `podzone-dashboard-ingress.yaml`
- `podzone-musings-ingress.yaml`
- `podzone-plone-ingress.yaml`

### Certificate configuration

LetsEncrypt https certificates are used for https ingress. The CertificateManager add on is required.

- `sudo microk8s enable cert-manager`

For implementation details see the following files in config/ directory:

- `podzone-certificateIssuer.yaml`
- `podzone-certs.yaml`

### Persistent data

Due to unsolved issues with postgres and Opensearch using NFS as a storage class, we use MicroSeph (using loopback devices at first).

Nodes:

- sigiriya
- james
- bukit

- sudo snap install microceph
- sudo microceph cluster bootstrap
- sudo microceph cluster add james
- sudo microceph cluster join eyJuYW1lIjoiamFtZXMiLCJzZWNyZXQiOiI4YzFhNWQwNDIwOGJhODRmNWVkMmEyZmE4YjAyNjI5ZjVlYzIzNzc5MTgzNDRlMGE5ZjIxMzVmOGJhMGI3OTg5IiwiZmluZ2VycHJpbnQiOiI4N2ZlZTY3NWQxYTVkN2E2Mzg1ZmIxZmM4OGNmYzJmNDc1ZWMxM2ViYjY4NWI5YmE3NzJiMGQ1OWNmZjQzN2RhIiwiam9pbl9hZGRyZXNzZXMiOlsiMTkyLjE2OC4wLjY6NzQ0MyJdfQ==


- microceph cluster add bukit
sudo microceph cluster join 
eyJuYW1lIjoiYnVraXQiLCJzZWNyZXQiOiJhNmJiZGU2N2Q1ZmVlYWQ3NGM4N2QxM2JjMjA2NzQyMDM5YzZmMWU3NjU4MTE5N2EwZWZlMDE2YTBiOGE5YTEyIiwiZmluZ2VycHJpbnQiOiI4N2ZlZTY3NWQxYTVkN2E2Mzg1ZmIxZmM4OGNmYzJmNDc1ZWMxM2ViYjY4NWI5YmE3NzJiMGQ1OWNmZjQzN2RhIiwiam9pbl9hZGRyZXNzZXMiOlsiMTkyLjE2OC4wLjY6NzQ0MyJdfQ==

- Create and add disks

```bash
  #!/bin/bash
  loop_file="$(sudo mktemp -p /mnt XXXX.img)"
  sudo truncate -s 10G "${loop_file}"
  loop_dev="$(sudo losetup --show -f "${loop_file}")"
  minor="${loop_dev##/dev/loop}"
  sudo mknod -m 0660 "/dev/sdib" b 7 "${minor}"
  sudo microceph disk add --wipe "/dev/sdib"
```

- sudo microceph.ceph config set global osd_pool_default_size 2
- sudo microceph.ceph config set mgr mgr_standby_modules false
- sudo microceph.ceph config set osd osd_crush_chooseleaf_type 0



Configure microk8s cluster:

- sudo microk8s enable rook-ceph

- Configs in `/var/snap/microceph/current/conf`
- We need ceph.conf, and ceph.keyring to attach

- ceph.conf:

```conf
# # Generated by MicroCeph, DO NOT EDIT.
[global]
run dir = /var/snap/microceph/707/run
fsid = 717715ab-d64d-42fe-9219-486015d2c166
mon host = 192.168.0.6,192.168.0.27,192.168.0.52
auth allow insecure global id reclaim = false
public addr = 192.168.0.6
ms bind ipv4 = true
ms bind ipv6 = false
```

- ceph.keyring:

```conf
# Generated by MicroCeph, DO NOT EDIT.
[client.admin]
    key = AQDwEitlF3HlExAAwoDaTsqvTw6opWst4Ckq+g==
```


```bash
 sudo microk8s connect-external-ceph --ceph-conf ceph.conf --keyring ceph.keyring --rbd-pool rbd
```

- test: `sudo microk8s kubectl --namespace rook-ceph-external get cephcluster`


### Upgrade: NOTE: did not result in rook-ceph add-on being available

sudo microk8s disable dashboard
microk8s disable metrics-server
microk8s kubectl drain sigiriya --ignore-daemonsets
- sudo snap refresh microk8s --channel=1.28/stable
- microk8s kubectl uncordon sigiriya

### Application installation (to be automated)

For implementation details see the following files in config/ directory:

- web server: `podzone-apache.yaml``
- Plone: `podzone-plone.yaml``
- Git Sync: podzone-git-sync.yaml

### Supporting Infrastructure

- `sudo snap install prometheus`: Available on localhost:9090

### Opensearch

- Edit `https://github.com/opensearch-project/helm-charts/blob/main/charts/opensearch/values.yaml` for opensearch-bukit.yaml, opensearch-james.yaml, opensearch-sigiriya.yaml
- `helm repo add opensearch https://opensearch-project.github.io/helm-charts/`
- `helm install opensearch-master opensearch/opensearch -f opensearch-bukit.yaml`
- `helm install opensearch-client opensearch/opensearch -f opensearch-james.yaml`
- `helm install opensearch-data opensearch/opensearch -f opensearch-sigiriya.yaml`
- `helm install dashboards opensearch/opensearch-dashboards`

### Zope

- Initial install of Plone, provides Zope 4, which is not backward compatable with the Zope 2 applications, so use a legacy zope image.
- Zope volume mounts: ./var/filestorage; ./var/blobstorage; ./products
